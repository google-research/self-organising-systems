{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVB7rEnodRT_"
      },
      "source": [
        "# **Transformers learn in-context by gradient descent**\n",
        "This specific notebook can be used to reproduce the results that assumes the standard token construction i.e. where $e_{2i} = x_i, e_{2i+1} = y_i$. We here show that the Transformer needs to first copy over neighboring tokens after which it can perform gradient descent steps in the following self-attention layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install requirements\n",
        "!wget -O requirements.txt https://raw.githubusercontent.com/google-research/self-organising-systems/master/transformers_learn_icl_by_gd/requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "FR8YNR-g9JXA"
      },
      "outputs": [],
      "source": [
        "#@title Imports external sources\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pylab as pl\n",
        "import numpy as np\n",
        "import glob\n",
        "import requests\n",
        "import random as pyrandom\n",
        "from concurrent import futures\n",
        "from functools import partial\n",
        "from scipy.ndimage import rotate\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import time\n",
        "from typing import Any, MutableMapping, NamedTuple, Tuple\n",
        "import jax\n",
        "from jax import grad, jit, vmap\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import haiku as hk\n",
        "import math\n",
        "from ml_collections import config_dict\n",
        "import matplotlib.pylab as pl\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.colormaps['Dark2'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "933ztM3DSREA",
        "outputId": "87d98f4e-5310-4568-d8db-cc26830d5ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers-learn-in-context-by-gradient-descent\n"
          ]
        }
      ],
      "source": [
        "#@title Import internal sources (from github)\n",
        "!git clone --quiet https://github.com/google-research/self-organising-systems.git /content/self-organising-systems \u003e /dev/null 2\u003e\u00261\n",
        "%cd /content/self-organising-systems/transformers_learn_icl_by_gd\n",
        "from src.transformer import Transformer\n",
        "from src.data import create_reg_data_classic_token, create_weights\n",
        "from src.config import config\n",
        "from src.train import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDXV8OJVoX4b"
      },
      "source": [
        "In the following you can play around with the experimental setup. \n",
        "A couple of things to note: \n",
        "\n",
        "1.   **use_softmax_only_in_the_first_layer** chooses if we want to use a softmax self-attention in the first layer. This seems to be neccessary to learn to copy in the first layer.  \n",
        "\n",
        "2. **num_seeds** \u003e 1 will rerun and show results of the experiment with the same config but with multiple seeds. For quick execution set this to 1.\n",
        "\n",
        "3. The experiments run much quicker when using a GPU or TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "4KwAI4LZFfcF"
      },
      "outputs": [],
      "source": [
        "#@title Config\n",
        "use_softmax = False #@param {type:\"boolean\"}\n",
        "use_softmax_only_in_the_first_layer = True #@param {type:\"boolean\"}\n",
        "num_layers = 2 #@param {type:\"integer\"}\n",
        "num_heads = 1 #@param {type:\"integer\"}\n",
        "num_seeds = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@title Config\n",
        "config.classic_token_const = True\n",
        "config.seed = 0\n",
        "\n",
        "if use_softmax_only_in_the_first_layer:\n",
        "  assert use_softmax == False\n",
        "  \n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "config.local_usage = True\n",
        "config.distract_size = 0\n",
        "config.training_steps = 10000\n",
        "config.training_steps_gd = 10000\n",
        "config.use_softmax = use_softmax \n",
        "config.first_layer_sm = use_softmax_only_in_the_first_layer \n",
        "config.use_non_lin_mix = False \n",
        "\n",
        "####\n",
        "config.deq = False\n",
        "config.att_only_trans = True\n",
        "####\n",
        "\n",
        "config.layer_norm = False\n",
        "config.out_proj = False\n",
        "config.in_proj = False\n",
        "config.adam = True\n",
        "config.pre_train_gd = True\n",
        "config.dataset_size = 10\n",
        "config.input_size = 10\n",
        "config.num_layers = num_layers\n",
        "config.num_heads = num_heads\n",
        "\n",
        "config.grad_clip_value = 10\n",
        "config.lr = 0.001\n",
        "\n",
        "config.wd = 0.0\n",
        "config.init_scale = 0.02 / config.num_layers\n",
        "config.bs = 2048\n",
        "\n",
        "config.dropout_rate = 0.0\n",
        "data_creator = vmap(create_reg_data_classic_token,\n",
        "                    in_axes=(0, None, None, None, None, None),\n",
        "                    out_axes=0)\n",
        "\n",
        "config.y_update = False\n",
        "config.input_range = 1\n",
        "config.seed = 0\n",
        "\n",
        "config.gd_deq = True \n",
        "config.pos_enc = True\n",
        "config.pos_enc_size = 10\n",
        "config.concat_pos_enc = True\n",
        "config.key_size = 20\n",
        "config.analyse = False\n",
        "\n",
        "config.ana_copy  = True\n",
        "config.num_seeds = num_seeds\n",
        "\n",
        "change_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "z9P7XZf7rh6l"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "pl.rcParams.update({'font.size': 12})\n",
        "pl.rc('axes', labelsize=14)\n",
        "pl.rcParams.update({\n",
        "    \"text.usetex\": False,\n",
        "})\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.colormaps['Dark2'] \n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb') #GFile.open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "def grab_plot(close=True):\n",
        "  \"\"\"Return the current Matplotlib figure as an image.\"\"\"\n",
        "  fig = pl.gcf()\n",
        "  fig.canvas.draw()\n",
        "  img = np.array(fig.canvas.renderer._renderer)\n",
        "  a = np.float32(img[..., 3:]/255.0)\n",
        "  img = np.uint8(255*(1.0-a) + img[...,:3] * a)  # alpha\n",
        "  if close:\n",
        "    pl.close()\n",
        "  return img\n",
        "\n",
        "def display_learning(train, test=None, gt=None, inter=None, title=\"train\", \n",
        "                     title1=\"Trained TF\", title2=\"Test\", \n",
        "                     title3='Gradient descent', title4='Interpolated',\n",
        "                     y_label1 = 'L2 Norm', y_label2 = 'Cosine sim',\n",
        "                     y_lim_l=0,  y_lim_u=1, single_seeds= False,\n",
        "                     plot_title = None,\n",
        "                     y_lim_u2= 1., y_lim_l2=0.,  x_label = 'Training steps',   \n",
        "                     second_axis=False, color_add=0, rw=10, num_iter_os=None, \n",
        "                     allow_download=False, plot_num=1, two_plots=False, \n",
        "                     loc_first = 'upper left', label_title=\"Loss\",\n",
        "                     loc_sec='upper left', yscale_log=False, line=\"-\",\n",
        "                     color_axis=True, \n",
        "                     height=3.5, width = 4, ax1=None, ax2=None):\n",
        "  \n",
        "  \"\"\"Update learning curve image.\"\"\"\n",
        "\n",
        "  train_list = train\n",
        "  train = np.array(train)\n",
        "  num_seeds_train = train.shape[0]\n",
        "  train_std = np.std(train, axis=0)\n",
        "  train = np.mean(train, axis=0)\n",
        "  \n",
        "  if test is not None:\n",
        "    test_list = test\n",
        "    test_std = np.std(test, axis=0)\n",
        "    test = np.mean(test, axis=0)\n",
        "\n",
        "  if gt is not None:\n",
        "    gt_list = gt\n",
        "    gt_std = np.std(gt, axis=0)\n",
        "    gt = np.mean(gt, axis=0)\n",
        "\n",
        "  if inter is not None:\n",
        "    inter_list = inter\n",
        "    inter_std = np.std(inter, axis=0)\n",
        "    inter = np.mean(inter, axis=0)\n",
        "\n",
        "  if plot_num == 1:\n",
        "    fig, ax1 = pl.subplots()\n",
        "    ax1.set_xlabel(x_label)\n",
        "    fig.set_size_inches(width, height)\n",
        "\n",
        "  \n",
        "  if test is not None and not second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(test)))\n",
        "    if len(test_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in test_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.1+color_add), alpha=0.2, linewidth='2')\n",
        "      else:\n",
        "        ax1.fill_between(x_range, test-test_std, test+test_std ,alpha=0.2, facecolor=colors(0.1+color_add))\n",
        "    ax1.plot(x_range[:len(test)], test, color=colors(0.1+color_add), label=title2,linewidth='3')\n",
        "    #test_avg = moving_average(test, rw)\n",
        "    #ax1.plot(x_range[:len(test_avg)], test_avg, color=colors(0.1+color_add), label=title2)\n",
        "      \n",
        "  if gt is not None:\n",
        "    if not second_axis:\n",
        "      x_range = np.arange(0, num_iter_os, int(num_iter_os/len(gt)))\n",
        "      #ax1.plot(x_range[:len(gt[:-rw])], gt[:-rw], color=colors(0.2+color_add), alpha=0.3)\n",
        "      #gt_avg = moving_average(gt, rw)\n",
        "      ax1.plot(x_range[:len(gt)],gt, color=colors(0.2+color_add), label=title3,linewidth='3')\n",
        "      if len(gt_list) \u003e 1:\n",
        "        if single_seeds:\n",
        "          for s in gt_list:\n",
        "            ax1.plot(x_range, s, color=colors(0.2+color_add), alpha=0.2, linewidth='2', zorder=0)\n",
        "        else:\n",
        "          ax1.fill_between(x_range, gt-gt_std, gt+gt_std,alpha=0.2, facecolor=colors(0.2+color_add))\n",
        "    else:\n",
        "      x_range = np.arange(0, num_iter_os, int(num_iter_os/len(gt)))\n",
        "      ax1.plot(x_range, gt, color=colors(0.6+color_add), label=title3,linewidth='3')\n",
        "      if len(gt_list) \u003e 1:\n",
        "        if single_seeds:\n",
        "          for s in gt_list:\n",
        "            ax1.plot(x_range, s, color=colors(0.6+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "        else:\n",
        "          ax1.fill_between(x_range, gt-gt_std, gt+gt_std ,alpha=0.2, facecolor=colors(0.6+color_add))\n",
        "\n",
        "  if test is not None and second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(test)))\n",
        "    ax1.plot(x_range[:len(test[:-rw])], test[:-rw], color=colors(0.5+color_add), label=title2,linewidth='3')\n",
        "    #test_avg = moving_average(test, rw)\n",
        "    #ax1.plot(x_range[:len(test_avg)],test_avg, color=colors(0.5+color_add))\n",
        "    if len(test_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in test_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.5+color_add), linewidth='2', alpha=0.3, zorder=0)\n",
        "      else:\n",
        "        ax1.fill_between(x_range, test-test_std, test+test_std ,alpha=0.2, facecolor=colors(0.5+color_add))\n",
        "\n",
        "  if inter is not None and not second_axis:\n",
        "    print(num_iter_os, int(num_iter_os/len(inter)))\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(inter)))\n",
        "    ax1.plot(x_range, inter, color=colors(0.4+color_add), label=title4, linewidth='3', zorder=10)\n",
        "    if len(inter_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in inter_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.4+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else:\n",
        "        ax1.fill_between(x_range, inter-inter_std, inter+inter_std ,alpha=0.2, facecolor=colors(0.4+color_add), zorder=1)\n",
        "    #inter_avg = moving_average(inter, rw)\n",
        "    #ax1.plot(x_range[:len(inter_avg)], inter_avg, color=colors(0.7+color_add), label=title4)\n",
        "\n",
        "  if second_axis:\n",
        "    if ax2 is None:\n",
        "      ax2 = ax1.twinx()\n",
        "    ax2.set_zorder(0)\n",
        "    ax1.set_zorder(1)\n",
        "    ax1.set_frame_on(False)\n",
        "    #train_avg = moving_average(train, rw)\n",
        "    #ax2.plot(train[:-rw], color=colors(0.1+color_add), alpha=0.3)\n",
        "    ax2.plot(x_range, train, color=colors(0.4+color_add), label=title1, linewidth='3')\n",
        "    ax2.plot(x_range, np.ones_like(train), \"--\", color=\"gray\", linewidth='0.7')\n",
        "    if len(train_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in train_list:\n",
        "          ax1.plot(x_range, s, line, color=colors(0.4+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else:\n",
        "        ax2.fill_between(x_range, train-train_std, train+train_std ,alpha=0.2, facecolor=colors(0.4+color_add))\n",
        "\n",
        "    if color_axis:\n",
        "      ax2.yaxis.label.set_color(colors(0.4+color_add))\n",
        "    else:\n",
        "      legend2 = ax2.legend(loc='upper right', framealpha=0.99, facecolor='white')\n",
        "      legend2.set_zorder(100)\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "  else:\n",
        "    #train_avg = moving_average(train, rw)\n",
        "    if line != \"-\":\n",
        "      ax1.scatter(x_range, train, s=[100 for _ in x_range], \n",
        "                  marker=\"+\", color=colors(0.3+color_add), alpha=1, label=title1, zorder=3, linewidths=3)\n",
        "    else:\n",
        "      ax1.plot(x_range, train, line, color=colors(0.3+color_add), label=title1, linewidth='3', zorder=11)\n",
        "    #ax1.plot(x_range[:len(train_avg)], train_avg, line, color=colors(0.3+color_add), label=title1)\n",
        "    if len(train_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "          for s in train_list:\n",
        "            ax1.plot(x_range, s, line, color=colors(0.3+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else: \n",
        "        ax1.fill_between(x_range, train-train_std, train+train_std,\n",
        "                       alpha=0.5, facecolor=colors(0.3+color_add))\n",
        "\n",
        "    ax1.legend(loc='best', framealpha=1, facecolor='white')\n",
        "    ax1.spines['right'].set_visible(False)\n",
        "    legend = ax1.legend(loc='upper right', framealpha=0.99, facecolor='white')\n",
        "    legend.set_zorder(100)\n",
        "  \n",
        "  legend1 = ax1.legend(loc=loc_first, framealpha=0.99, facecolor='white')\n",
        "  legend1.set_zorder(100)\n",
        "  if second_axis:\n",
        "    ax2.set_ylabel(y_label2)\n",
        "    ax1.set_ylabel(y_label1)\n",
        "    ax1.set_ylim(y_lim_l, y_lim_u)\n",
        "    legend1 = ax1.legend(loc=loc_sec, framealpha=0.99, facecolor='white')\n",
        "    ax2.set_ylim(y_lim_l2, y_lim_u2)\n",
        "    ax1.set_ylim(bottom=0)\n",
        "  else:\n",
        "    pl.ylabel(label_title)\n",
        "    pl.ylim(y_lim_l, y_lim_u)\n",
        "  ax1.spines['top'].set_visible(False)\n",
        "  \n",
        "  if plot_title is not None:\n",
        "    pl.title(plot_title)\n",
        "    \n",
        "  if yscale_log:\n",
        "    ax1.set_yscale(\"log\")\n",
        "  #pl.title(title)\n",
        "  pl.tight_layout()\n",
        "\n",
        "  if allow_download:\n",
        "    if second_axis:\n",
        "      pl.savefig(\"sim.pdf\", format=\"pdf\")\n",
        "      %download_file sim.pdf\n",
        "    else:\n",
        "      pl.savefig(\"train.pdf\", format=\"pdf\")\n",
        "      %download_file train.pdf\n",
        "  else:\n",
        "    img = grab_plot()\n",
        "    display(Image(data=imencode(img, fmt='jpeg')), display_id=title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "-yKhegD9rxRw"
      },
      "outputs": [],
      "source": [
        "#@title Lists\n",
        "\n",
        "loss_trans_list =  [[]  for _ in range(config.num_seeds)]\n",
        "own_list =  [[]  for _ in range(config.num_seeds)]\n",
        "own_one_list =  [[]  for _ in range(config.num_seeds)]\n",
        "other_list =  [[]  for _ in range(config.num_seeds)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bkrJZd5M9Dee"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "eval_rng = jax.random.PRNGKey(10)\n",
        "for cur_seed in range(0, config.num_seeds):\n",
        "  config.seed = cur_seed  \n",
        "  optimiser, train_state, _, rng = init()\n",
        "  rng, data_rng, eval_rng = jax.random.split(rng, 3)\n",
        "\n",
        "  eval_data = data_creator(jax.random.split(eval_rng, num=10000),\n",
        "                               config.input_size,\n",
        "                               config.dataset_size,\n",
        "                               config.size_distract,\n",
        "                               config.input_range,\n",
        "                               config.weight_scale)\n",
        "  \n",
        "  for step in range(config.training_steps):\n",
        "    rng, data_rng = jax.random.split(data_rng, 2)\n",
        "    train_data = data_creator(jax.random.split(rng, num=config.bs), \n",
        "                              config.input_size,\n",
        "                              config.dataset_size,\n",
        "                              config.size_distract,\n",
        "                              config.input_range,\n",
        "                              config.weight_scale)\n",
        "    train_state, metrics = update(train_state, train_data, optimiser)\n",
        "    if step % 500 == 0:\n",
        "      loss_trans, _, _ = predict_test.apply(train_state.params, eval_rng,\n",
        "                                            eval_data, False)\n",
        "      own, own_one, other = analyse_copy(eval_data, train_state, eval_rng)\n",
        "\n",
        "      loss_trans_list[cur_seed].append(loss_trans)\n",
        "      own_list[cur_seed].append(own)\n",
        "      own_one_list[cur_seed].append(own_one)\n",
        "      other_list[cur_seed].append(other)\n",
        "      display((\"Current seed\", cur_seed, \"Training step\", step,\n",
        "                    \"Trained TF loss\", loss_trans.item(),\n",
        "                    \"Norm grad to own token\", own.item(), \n",
        "                    \"Norm grad to next token\", own_one.item(), \n",
        "                    \"Norm grad to all other tokens\", other.item()),\n",
        "                    display_id=\"Cur met\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fY1XpXEFvlgq"
      },
      "outputs": [],
      "source": [
        "#@title Visualize Loss\n",
        "losses_gd_list = [0.20468888]*len(loss_trans_list[0]) \n",
        "other_list_half = [o[:100] for o in other_list]\n",
        "own_list_half = [o[:100] for o in own_list]\n",
        "own_one_list_half = [o[:100] for o in own_one_list]\n",
        "display_learning(loss_trans_list, [losses_gd_list], y_lim_u=0.55, y_lim_l=0.2,\n",
        "                 loc_first='upper right', color_add=0.0, title2='GD 1 step', title1=\"TF 2 layers\",\n",
        "                 rw=1, title=\"train.pdf\", allow_download=False, single_seeds=True,\n",
        "                 num_iter_os=len(losses_gd_list)*500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TGNtmHIR0kFe"
      },
      "outputs": [],
      "source": [
        "#@title Visualize sensitivity\n",
        "display_learning(other_list_half, own_list_half, own_one_list_half, y_lim_u=3.5, y_lim_l=0.0,\n",
        "                title3=r\"$\\partial t(e_j) / \\partial e_{j+1}$\", title2=\"$\\partial t(e_j) / \\partial e_{j}$\", title1=\"$\\partial t(e_j) / \\partial e_{other}$\",\n",
        "                 loc_first='center left', color_add=0.5, label_title=\"Norm part. derivatives\",\n",
        "                 rw=1, title=\"train.pdf\", allow_download=False, single_seeds=True,\n",
        "                 num_iter_os=len(losses_gd_list)*500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WEg8Z-Vu3792"
      },
      "outputs": [],
      "source": [
        "#@title Visualize attn heads\n",
        "pl.rcParams.update({'font.size': 12})\n",
        "pl.rc('axes', labelsize=14)\n",
        "pl.rcParams.update({\n",
        "    \"text.usetex\": False,\n",
        "})\n",
        "\n",
        "\n",
        "attn = predict_attn.apply(train_state.params, eval_rng,\n",
        "                                            eval_data[0], False)\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.cm.get_cmap('Dark2')\n",
        "\n",
        "for n in range(config.num_layers):\n",
        "  for head in range(attn[n].shape[1]):\n",
        "    print(\"Layer \", n, \"Head \", head)\n",
        "    fig, (ax1, ax2) = pl.subplots(figsize=(7, 3), ncols=2)\n",
        "    ax1.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax1.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax1.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax1.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "\n",
        "    ax2.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax2.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax2.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax2.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "    \n",
        "    ax1.set_xlabel(\"Key\")\n",
        "    ax1.set_title(\"Single task act. of $K^TQ$\")\n",
        "    ax1.set_ylabel(\"Query\")\n",
        "    ax2.set_xlabel(\"Key\")\n",
        "    ax2.set_title(\"Task avg act. of $K^TQ$\")\n",
        "    single = jnp.squeeze(attn[n][0, head, :, :])\n",
        "    mean = jnp.mean(attn[n][:, head, :, :], axis=0)\n",
        "    vmin = jnp.max(jnp.abs(single))\n",
        "    vmin2 = jnp.max(jnp.abs(mean))\n",
        "    vmin = np.max([vmin, vmin2])\n",
        "    pos = ax1.imshow(single, cmap='RdBu', vmin=-vmin, vmax=vmin)\n",
        "    fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "    pos = ax2.imshow(mean, cmap='RdBu', vmin=-vmin, vmax=vmin)\n",
        "    fig.colorbar(pos, ax=ax2, shrink=1)\n",
        "    pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P-o8KWv9oX4d"
      },
      "outputs": [],
      "source": [
        "#@title Visualize attn heads for single tasks for layer 1\n",
        "\n",
        "for i in range(5):\n",
        "  fig, ax1 = pl.subplots(figsize=(4, 3))\n",
        "  ax1.set_title(\"Task \" + str(i) + \" activation of $K^TQ$\")\n",
        "  single = jnp.squeeze(attn[0][i, 0, :, :])\n",
        "  vmin = jnp.max(jnp.abs(single))\n",
        "  pos = ax1.imshow(single, cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "  fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "  pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bKHbCrejdzkr"
      },
      "outputs": [],
      "source": [
        "#@title Visualize attn heads for single tasks for layer 2\n",
        "\n",
        "for i in range(5):\n",
        "  fig, ax1 = pl.subplots(figsize=(4, 3))\n",
        "  ax1.set_title(\"Task \" + str(i) + \" activation of $K^TQ$\")\n",
        "  single = jnp.squeeze(attn[1][i, 0, :, :])\n",
        "  vmin = jnp.max(jnp.abs(single))\n",
        "  pos = ax1.imshow(single, cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "  fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "  pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCaZYhNdLJm4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Visualize weights\n",
        "num_dim = config.key_size\n",
        "for n in range(config.num_layers):\n",
        "  for head in range(config.num_heads):\n",
        "    KQ = jnp.identity(num_dim)\n",
        "    LV = jnp.identity(num_dim)\n",
        "    print(\"Layer \", n, \"Head \", head)\n",
        "    fig, (ax1, ax2) = pl.subplots(figsize=(9, 3), ncols=2)\n",
        "  \n",
        "    ax1.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax1.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax1.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax1.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "\n",
        "    ax2.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax2.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax2.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax2.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "\n",
        "    for k,v in train_state.params.items():\n",
        "      if str(n) in k:\n",
        "        #print(k, head, v['w'].shape)\n",
        "        #print(k, head, v['w'].shape, )\n",
        "        if \"key\" in k:\n",
        "          KQ = jnp.matmul(KQ, v['w'][:, head*num_dim: (head+1)*num_dim])\n",
        "        elif \"query\" in k:\n",
        "          KQ = jnp.matmul(KQ, v['w'][:, head*num_dim: (head+1)*num_dim].T)\n",
        "        elif \"value\" in k:\n",
        "          LV = jnp.matmul(v['w'][:, head*num_dim: (head+1)*num_dim], LV)\n",
        "        elif \"linear\" in k:\n",
        "          LV = jnp.matmul(v['w'][head*num_dim: (head+1)*num_dim, :], LV)\n",
        "\n",
        "    vmin = jnp.max(jnp.abs(KQ))\n",
        "    vmin2 = jnp.max(jnp.abs(LV))\n",
        "    vmin = np.max([vmin, vmin2])\n",
        "\n",
        "    ax2.set_title(\"Weight of $PW_V$\")\n",
        "    ax1.set_title(\"Weights of $W^T_KW_V$\")  \n",
        "    pos = ax1.imshow(KQ,cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "    fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "    pos = ax2.imshow(LV, cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "    fig.colorbar(pos, ax=ax2, shrink=1)\n",
        "    pl.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "normal_token_setup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
