{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVB7rEnodRT_"
      },
      "source": [
        "# **Transformers learn in-context by gradient descent**\n",
        "This specific notebook can be used to reproduce the results that assumes the standard token construction i.e. where $e_{2i} = x_i, e_{2i+1} = y_i$. We here show that the Transformer needs to first copy over neighboring tokens after which it can perform gradient descent steps in the following self-attention layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "FR8YNR-g9JXA"
      },
      "outputs": [],
      "source": [
        "#@title Imports external sources\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pylab as pl\n",
        "import numpy as np\n",
        "import glob\n",
        "import requests\n",
        "import random as pyrandom\n",
        "from concurrent import futures\n",
        "from functools import partial\n",
        "from scipy.ndimage import rotate\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import time\n",
        "from typing import Any, MutableMapping, NamedTuple, Tuple\n",
        "!pip install --quiet --upgrade tensorflow \n",
        "!pip install --quiet --upgrade jax\n",
        "!pip install --quiet --upgrade jaxlib \n",
        "import jax\n",
        "from jax import grad, jit, vmap\n",
        "import jax.numpy as jnp\n",
        "\n",
        "!pip install --quiet -U dm-haiku\n",
        "!pip install --quiet -U optax\n",
        "import haiku as hk\n",
        "import math\n",
        "!pip install --quiet -U ml_collections\n",
        "from ml_collections import config_dict\n",
        "import matplotlib.pylab as pl\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.colormaps['Dark2'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "933ztM3DSREA",
        "outputId": "87d98f4e-5310-4568-d8db-cc26830d5ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers-learn-in-context-by-gradient-descent\n"
          ]
        }
      ],
      "source": [
        "#@title Import internal sources (from github)\n",
        "!git clone --quiet https://github.com/google-research/self-organising-systems.git /content/self-organising-systems \u003e /dev/null 2\u003e\u00261\n",
        "%cd /content/self-organising-systems/transformers_learn_icl_by_gd\n",
        "from src.transformer import Transformer\n",
        "from src.data import create_reg_data_classic_token, create_weights\n",
        "from src.config import config\n",
        "from src.train import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDXV8OJVoX4b"
      },
      "source": [
        "In the following you can play around with the experimental setup. \n",
        "A couple of things to note: \n",
        "\n",
        "1.   **use_softmax_only_in_the_first_layer** chooses if we want to use a softmax self-attention in the first layer. This seems to be neccessary to learn to copy in the first layer.  \n",
        "\n",
        "2. **num_seeds** \u003e 1 will rerun and show results of the experiment with the same config but with multiple seeds. For quick execution set this to 1.\n",
        "\n",
        "3. The experiments run much quicker when using a GPU or TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "4KwAI4LZFfcF"
      },
      "outputs": [],
      "source": [
        "#@title Config\n",
        "use_softmax = False #@param {type:\"boolean\"}\n",
        "use_softmax_only_in_the_first_layer = True #@param {type:\"boolean\"}\n",
        "num_layers = 2 #@param {type:\"integer\"}\n",
        "num_heads = 1 #@param {type:\"integer\"}\n",
        "num_seeds = 1 #@param {type:\"integer\"}\n",
        "\n",
        "#@title Config\n",
        "config.classic_token_const = True\n",
        "config.seed = 0\n",
        "\n",
        "if use_softmax_only_in_the_first_layer:\n",
        "  assert use_softmax == False\n",
        "  \n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "config.local_usage = True\n",
        "config.distract_size = 0\n",
        "config.training_steps = 10000\n",
        "config.training_steps_gd = 10000\n",
        "config.use_softmax = use_softmax \n",
        "config.first_layer_sm = use_softmax_only_in_the_first_layer \n",
        "config.use_non_lin_mix = False \n",
        "\n",
        "####\n",
        "config.deq = False\n",
        "config.att_only_trans = True\n",
        "####\n",
        "\n",
        "config.layer_norm = False\n",
        "config.out_proj = False\n",
        "config.in_proj = False\n",
        "config.adam = True\n",
        "config.pre_train_gd = True\n",
        "config.dataset_size = 10\n",
        "config.input_size = 10\n",
        "config.num_layers = num_layers\n",
        "config.num_heads = num_heads\n",
        "\n",
        "config.grad_clip_value = 10\n",
        "config.lr = 0.001\n",
        "\n",
        "config.wd = 0.0\n",
        "config.init_scale = 0.02 / config.num_layers\n",
        "config.bs = 2048\n",
        "\n",
        "config.dropout_rate = 0.0\n",
        "data_creator = vmap(create_reg_data_classic_token,\n",
        "                    in_axes=(0, None, None, None, None, None),\n",
        "                    out_axes=0)\n",
        "\n",
        "config.y_update = False\n",
        "config.input_range = 1\n",
        "config.seed = 0\n",
        "\n",
        "config.gd_deq = True \n",
        "config.pos_enc = True\n",
        "config.pos_enc_size = 10\n",
        "config.concat_pos_enc = True\n",
        "config.key_size = 20\n",
        "config.analyse = False\n",
        "\n",
        "config.ana_copy  = True\n",
        "config.num_seeds = num_seeds\n",
        "\n",
        "change_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "z9P7XZf7rh6l"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "pl.rcParams.update({'font.size': 12})\n",
        "pl.rc('axes', labelsize=14)\n",
        "pl.rcParams.update({\n",
        "    \"text.usetex\": False,\n",
        "})\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.colormaps['Dark2'] \n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb') #GFile.open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "def grab_plot(close=True):\n",
        "  \"\"\"Return the current Matplotlib figure as an image.\"\"\"\n",
        "  fig = pl.gcf()\n",
        "  fig.canvas.draw()\n",
        "  img = np.array(fig.canvas.renderer._renderer)\n",
        "  a = np.float32(img[..., 3:]/255.0)\n",
        "  img = np.uint8(255*(1.0-a) + img[...,:3] * a)  # alpha\n",
        "  if close:\n",
        "    pl.close()\n",
        "  return img\n",
        "\n",
        "def display_learning(train, test=None, gt=None, inter=None, title=\"train\", \n",
        "                     title1=\"Trained TF\", title2=\"Test\", \n",
        "                     title3='Gradient descent', title4='Interpolated',\n",
        "                     y_label1 = 'L2 Norm', y_label2 = 'Cosine sim',\n",
        "                     y_lim_l=0,  y_lim_u=1, single_seeds= False,\n",
        "                     plot_title = None,\n",
        "                     y_lim_u2= 1., y_lim_l2=0.,  x_label = 'Training steps',   \n",
        "                     second_axis=False, color_add=0, rw=10, num_iter_os=None, \n",
        "                     allow_download=False, plot_num=1, two_plots=False, \n",
        "                     loc_first = 'upper left', label_title=\"Loss\",\n",
        "                     loc_sec='upper left', yscale_log=False, line=\"-\",\n",
        "                     color_axis=True, \n",
        "                     height=3.5, width = 4, ax1=None, ax2=None):\n",
        "  \n",
        "  \"\"\"Update learning curve image.\"\"\"\n",
        "\n",
        "  train_list = train\n",
        "  train = np.array(train)\n",
        "  num_seeds_train = train.shape[0]\n",
        "  train_std = np.std(train, axis=0)\n",
        "  train = np.mean(train, axis=0)\n",
        "  \n",
        "  if test is not None:\n",
        "    test_list = test\n",
        "    test_std = np.std(test, axis=0)\n",
        "    test = np.mean(test, axis=0)\n",
        "\n",
        "  if gt is not None:\n",
        "    gt_list = gt\n",
        "    gt_std = np.std(gt, axis=0)\n",
        "    gt = np.mean(gt, axis=0)\n",
        "\n",
        "  if inter is not None:\n",
        "    inter_list = inter\n",
        "    inter_std = np.std(inter, axis=0)\n",
        "    inter = np.mean(inter, axis=0)\n",
        "\n",
        "  if plot_num == 1:\n",
        "    fig, ax1 = pl.subplots()\n",
        "    ax1.set_xlabel(x_label)\n",
        "    fig.set_size_inches(width, height)\n",
        "\n",
        "  \n",
        "  if test is not None and not second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(test)))\n",
        "    if len(test_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in test_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.1+color_add), alpha=0.2, linewidth='2')\n",
        "      else:\n",
        "        ax1.fill_between(x_range, test-test_std, test+test_std ,alpha=0.2, facecolor=colors(0.1+color_add))\n",
        "    ax1.plot(x_range[:len(test)], test, color=colors(0.1+color_add), label=title2,linewidth='3')\n",
        "    #test_avg = moving_average(test, rw)\n",
        "    #ax1.plot(x_range[:len(test_avg)], test_avg, color=colors(0.1+color_add), label=title2)\n",
        "      \n",
        "  if gt is not None:\n",
        "    if not second_axis:\n",
        "      x_range = np.arange(0, num_iter_os, int(num_iter_os/len(gt)))\n",
        "      #ax1.plot(x_range[:len(gt[:-rw])], gt[:-rw], color=colors(0.2+color_add), alpha=0.3)\n",
        "      #gt_avg = moving_average(gt, rw)\n",
        "      ax1.plot(x_range[:len(gt)],gt, color=colors(0.2+color_add), label=title3,linewidth='3')\n",
        "      if len(gt_list) \u003e 1:\n",
        "        if single_seeds:\n",
        "          for s in gt_list:\n",
        "            ax1.plot(x_range, s, color=colors(0.2+color_add), alpha=0.2, linewidth='2', zorder=0)\n",
        "        else:\n",
        "          ax1.fill_between(x_range, gt-gt_std, gt+gt_std,alpha=0.2, facecolor=colors(0.2+color_add))\n",
        "    else:\n",
        "      x_range = np.arange(0, num_iter_os, int(num_iter_os/len(gt)))\n",
        "      ax1.plot(x_range, gt, color=colors(0.6+color_add), label=title3,linewidth='3')\n",
        "      if len(gt_list) \u003e 1:\n",
        "        if single_seeds:\n",
        "          for s in gt_list:\n",
        "            ax1.plot(x_range, s, color=colors(0.6+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "        else:\n",
        "          ax1.fill_between(x_range, gt-gt_std, gt+gt_std ,alpha=0.2, facecolor=colors(0.6+color_add))\n",
        "\n",
        "  if test is not None and second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(test)))\n",
        "    ax1.plot(x_range[:len(test[:-rw])], test[:-rw], color=colors(0.5+color_add), label=title2,linewidth='3')\n",
        "    #test_avg = moving_average(test, rw)\n",
        "    #ax1.plot(x_range[:len(test_avg)],test_avg, color=colors(0.5+color_add))\n",
        "    if len(test_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in test_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.5+color_add), linewidth='2', alpha=0.3, zorder=0)\n",
        "      else:\n",
        "        ax1.fill_between(x_range, test-test_std, test+test_std ,alpha=0.2, facecolor=colors(0.5+color_add))\n",
        "\n",
        "  if inter is not None and not second_axis:\n",
        "    print(num_iter_os, int(num_iter_os/len(inter)))\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(inter)))\n",
        "    ax1.plot(x_range, inter, color=colors(0.4+color_add), label=title4, linewidth='3', zorder=10)\n",
        "    if len(inter_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in inter_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.4+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else:\n",
        "        ax1.fill_between(x_range, inter-inter_std, inter+inter_std ,alpha=0.2, facecolor=colors(0.4+color_add), zorder=1)\n",
        "    #inter_avg = moving_average(inter, rw)\n",
        "    #ax1.plot(x_range[:len(inter_avg)], inter_avg, color=colors(0.7+color_add), label=title4)\n",
        "\n",
        "  if second_axis:\n",
        "    if ax2 is None:\n",
        "      ax2 = ax1.twinx()\n",
        "    ax2.set_zorder(0)\n",
        "    ax1.set_zorder(1)\n",
        "    ax1.set_frame_on(False)\n",
        "    #train_avg = moving_average(train, rw)\n",
        "    #ax2.plot(train[:-rw], color=colors(0.1+color_add), alpha=0.3)\n",
        "    ax2.plot(x_range, train, color=colors(0.4+color_add), label=title1, linewidth='3')\n",
        "    ax2.plot(x_range, np.ones_like(train), \"--\", color=\"gray\", linewidth='0.7')\n",
        "    if len(train_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in train_list:\n",
        "          ax1.plot(x_range, s, line, color=colors(0.4+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else:\n",
        "        ax2.fill_between(x_range, train-train_std, train+train_std ,alpha=0.2, facecolor=colors(0.4+color_add))\n",
        "\n",
        "    if color_axis:\n",
        "      ax2.yaxis.label.set_color(colors(0.4+color_add))\n",
        "    else:\n",
        "      legend2 = ax2.legend(loc='upper right', framealpha=0.99, facecolor='white')\n",
        "      legend2.set_zorder(100)\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "  else:\n",
        "    #train_avg = moving_average(train, rw)\n",
        "    if line != \"-\":\n",
        "      ax1.scatter(x_range, train, s=[100 for _ in x_range], \n",
        "                  marker=\"+\", color=colors(0.3+color_add), alpha=1, label=title1, zorder=3, linewidths=3)\n",
        "    else:\n",
        "      ax1.plot(x_range, train, line, color=colors(0.3+color_add), label=title1, linewidth='3', zorder=11)\n",
        "    #ax1.plot(x_range[:len(train_avg)], train_avg, line, color=colors(0.3+color_add), label=title1)\n",
        "    if len(train_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "          for s in train_list:\n",
        "            ax1.plot(x_range, s, line, color=colors(0.3+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else: \n",
        "        ax1.fill_between(x_range, train-train_std, train+train_std,\n",
        "                       alpha=0.5, facecolor=colors(0.3+color_add))\n",
        "\n",
        "    ax1.legend(loc='best', framealpha=1, facecolor='white')\n",
        "    ax1.spines['right'].set_visible(False)\n",
        "    legend = ax1.legend(loc='upper right', framealpha=0.99, facecolor='white')\n",
        "    legend.set_zorder(100)\n",
        "  \n",
        "  legend1 = ax1.legend(loc=loc_first, framealpha=0.99, facecolor='white')\n",
        "  legend1.set_zorder(100)\n",
        "  if second_axis:\n",
        "    ax2.set_ylabel(y_label2)\n",
        "    ax1.set_ylabel(y_label1)\n",
        "    ax1.set_ylim(y_lim_l, y_lim_u)\n",
        "    legend1 = ax1.legend(loc=loc_sec, framealpha=0.99, facecolor='white')\n",
        "    ax2.set_ylim(y_lim_l2, y_lim_u2)\n",
        "    ax1.set_ylim(bottom=0)\n",
        "  else:\n",
        "    pl.ylabel(label_title)\n",
        "    pl.ylim(y_lim_l, y_lim_u)\n",
        "  ax1.spines['top'].set_visible(False)\n",
        "  \n",
        "  if plot_title is not None:\n",
        "    pl.title(plot_title)\n",
        "    \n",
        "  if yscale_log:\n",
        "    ax1.set_yscale(\"log\")\n",
        "  #pl.title(title)\n",
        "  pl.tight_layout()\n",
        "\n",
        "  if allow_download:\n",
        "    if second_axis:\n",
        "      pl.savefig(\"sim.pdf\", format=\"pdf\")\n",
        "      %download_file sim.pdf\n",
        "    else:\n",
        "      pl.savefig(\"train.pdf\", format=\"pdf\")\n",
        "      %download_file train.pdf\n",
        "  else:\n",
        "    img = grab_plot()\n",
        "    display(Image(data=imencode(img, fmt='jpeg')), display_id=title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "-yKhegD9rxRw"
      },
      "outputs": [],
      "source": [
        "#@title Lists\n",
        "\n",
        "loss_trans_list =  [[]  for _ in range(config.num_seeds)]\n",
        "own_list =  [[]  for _ in range(config.num_seeds)]\n",
        "own_one_list =  [[]  for _ in range(config.num_seeds)]\n",
        "other_list =  [[]  for _ in range(config.num_seeds)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bkrJZd5M9Dee"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "eval_rng = jax.random.PRNGKey(10)\n",
        "for cur_seed in range(0, config.num_seeds):\n",
        "  config.seed = cur_seed  \n",
        "  optimiser, train_state, _, rng = init()\n",
        "  rng, data_rng, eval_rng = jax.random.split(rng, 3)\n",
        "\n",
        "  eval_data = data_creator(jax.random.split(eval_rng, num=10000),\n",
        "                               config.input_size,\n",
        "                               config.dataset_size,\n",
        "                               config.size_distract,\n",
        "                               config.input_range,\n",
        "                               config.weight_scale)\n",
        "  \n",
        "  for step in range(config.training_steps):\n",
        "    rng, data_rng = jax.random.split(data_rng, 2)\n",
        "    train_data = data_creator(jax.random.split(rng, num=config.bs), \n",
        "                              config.input_size,\n",
        "                              config.dataset_size,\n",
        "                              config.size_distract,\n",
        "                              config.input_range,\n",
        "                              config.weight_scale)\n",
        "    train_state, metrics = update(train_state, train_data, optimiser)\n",
        "    if step % 500 == 0:\n",
        "      loss_trans, _, _ = predict_test.apply(train_state.params, eval_rng,\n",
        "                                            eval_data, False)\n",
        "      own, own_one, other = analyse_copy(eval_data, train_state, eval_rng)\n",
        "\n",
        "      loss_trans_list[cur_seed].append(loss_trans)\n",
        "      own_list[cur_seed].append(own)\n",
        "      own_one_list[cur_seed].append(own_one)\n",
        "      other_list[cur_seed].append(other)\n",
        "      display((\"Current seed\", cur_seed, \"Training step\", step,\n",
        "                    \"Trained TF loss\", loss_trans.item(),\n",
        "                    \"Norm grad to own token\", own.item(), \n",
        "                    \"Norm grad to next token\", own_one.item(), \n",
        "                    \"Norm grad to all other tokens\", other.item()),\n",
        "                    display_id=\"Cur met\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fY1XpXEFvlgq"
      },
      "outputs": [],
      "source": [
        "#@title Visualize Loss\n",
        "losses_gd_list = [0.20468888]*len(loss_trans_list[0]) \n",
        "other_list_half = [o[:100] for o in other_list]\n",
        "own_list_half = [o[:100] for o in own_list]\n",
        "own_one_list_half = [o[:100] for o in own_one_list]\n",
        "display_learning(loss_trans_list, [losses_gd_list], y_lim_u=0.55, y_lim_l=0.2,\n",
        "                 loc_first='upper right', color_add=0.0, title2='GD 1 step', title1=\"TF 2 layers\",\n",
        "                 rw=1, title=\"train.pdf\", allow_download=False, single_seeds=True,\n",
        "                 num_iter_os=len(losses_gd_list)*500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TGNtmHIR0kFe"
      },
      "outputs": [],
      "source": [
        "#@title Visualize sensitivity\n",
        "display_learning(other_list_half, own_list_half, own_one_list_half, y_lim_u=3.5, y_lim_l=0.0,\n",
        "                title3=r\"$\\partial t(e_j) / \\partial e_{j+1}$\", title2=\"$\\partial t(e_j) / \\partial e_{j}$\", title1=\"$\\partial t(e_j) / \\partial e_{other}$\",\n",
        "                 loc_first='center left', color_add=0.5, label_title=\"Norm part. derivatives\",\n",
        "                 rw=1, title=\"train.pdf\", allow_download=False, single_seeds=True,\n",
        "                 num_iter_os=len(losses_gd_list)*500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WEg8Z-Vu3792"
      },
      "outputs": [],
      "source": [
        "#@title Visualize attn heads\n",
        "pl.rcParams.update({'font.size': 12})\n",
        "pl.rc('axes', labelsize=14)\n",
        "pl.rcParams.update({\n",
        "    \"text.usetex\": False,\n",
        "})\n",
        "\n",
        "\n",
        "attn = predict_attn.apply(train_state.params, eval_rng,\n",
        "                                            eval_data[0], False)\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.cm.get_cmap('Dark2')\n",
        "\n",
        "for n in range(config.num_layers):\n",
        "  for head in range(attn[n].shape[1]):\n",
        "    print(\"Layer \", n, \"Head \", head)\n",
        "    fig, (ax1, ax2) = pl.subplots(figsize=(7, 3), ncols=2)\n",
        "    ax1.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax1.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax1.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax1.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "\n",
        "    ax2.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax2.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax2.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax2.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "    \n",
        "    ax1.set_xlabel(\"Key\")\n",
        "    ax1.set_title(\"Single task act. of $K^TQ$\")\n",
        "    ax1.set_ylabel(\"Query\")\n",
        "    ax2.set_xlabel(\"Key\")\n",
        "    ax2.set_title(\"Task avg act. of $K^TQ$\")\n",
        "    single = jnp.squeeze(attn[n][0, head, :, :])\n",
        "    mean = jnp.mean(attn[n][:, head, :, :], axis=0)\n",
        "    vmin = jnp.max(jnp.abs(single))\n",
        "    vmin2 = jnp.max(jnp.abs(mean))\n",
        "    vmin = np.max([vmin, vmin2])\n",
        "    pos = ax1.imshow(single, cmap='RdBu', vmin=-vmin, vmax=vmin)\n",
        "    fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "    pos = ax2.imshow(mean, cmap='RdBu', vmin=-vmin, vmax=vmin)\n",
        "    fig.colorbar(pos, ax=ax2, shrink=1)\n",
        "    pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "P-o8KWv9oX4d"
      },
      "outputs": [],
      "source": [
        "#@title Visualize attn heads for single tasks for layer 1\n",
        "\n",
        "for i in range(5):\n",
        "  fig, ax1 = pl.subplots(figsize=(4, 3))\n",
        "  ax1.set_title(\"Task \" + str(i) + \" activation of $K^TQ$\")\n",
        "  single = jnp.squeeze(attn[0][i, 0, :, :])\n",
        "  vmin = jnp.max(jnp.abs(single))\n",
        "  pos = ax1.imshow(single, cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "  fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "  pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bKHbCrejdzkr"
      },
      "outputs": [],
      "source": [
        "#@title Visualize attn heads for single tasks for layer 2\n",
        "\n",
        "for i in range(5):\n",
        "  fig, ax1 = pl.subplots(figsize=(4, 3))\n",
        "  ax1.set_title(\"Task \" + str(i) + \" activation of $K^TQ$\")\n",
        "  single = jnp.squeeze(attn[1][i, 0, :, :])\n",
        "  vmin = jnp.max(jnp.abs(single))\n",
        "  pos = ax1.imshow(single, cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "  fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "  pl.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCaZYhNdLJm4",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Visualize weights\n",
        "num_dim = config.key_size\n",
        "for n in range(config.num_layers):\n",
        "  for head in range(config.num_heads):\n",
        "    KQ = jnp.identity(num_dim)\n",
        "    LV = jnp.identity(num_dim)\n",
        "    print(\"Layer \", n, \"Head \", head)\n",
        "    fig, (ax1, ax2) = pl.subplots(figsize=(9, 3), ncols=2)\n",
        "  \n",
        "    ax1.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax1.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax1.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax1.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "\n",
        "    ax2.set_yticks(ticks=range(0, config.key_size+1, 5))\n",
        "    ax2.set_yticklabels(range(1, config.key_size+2, 5))\n",
        "    ax2.set_xticks(ticks=range(0, config.key_size, 5))\n",
        "    ax2.set_xticklabels(range(1, config.key_size+1, 5))\n",
        "\n",
        "    for k,v in train_state.params.items():\n",
        "      if str(n) in k:\n",
        "        #print(k, head, v['w'].shape)\n",
        "        #print(k, head, v['w'].shape, )\n",
        "        if \"key\" in k:\n",
        "          KQ = jnp.matmul(KQ, v['w'][:, head*num_dim: (head+1)*num_dim])\n",
        "        elif \"query\" in k:\n",
        "          KQ = jnp.matmul(KQ, v['w'][:, head*num_dim: (head+1)*num_dim].T)\n",
        "        elif \"value\" in k:\n",
        "          LV = jnp.matmul(v['w'][:, head*num_dim: (head+1)*num_dim], LV)\n",
        "        elif \"linear\" in k:\n",
        "          LV = jnp.matmul(v['w'][head*num_dim: (head+1)*num_dim, :], LV)\n",
        "\n",
        "    vmin = jnp.max(jnp.abs(KQ))\n",
        "    vmin2 = jnp.max(jnp.abs(LV))\n",
        "    vmin = np.max([vmin, vmin2])\n",
        "\n",
        "    ax2.set_title(\"Weight of $PW_V$\")\n",
        "    ax1.set_title(\"Weights of $W^T_KW_V$\")  \n",
        "    pos = ax1.imshow(KQ,cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "    fig.colorbar(pos, ax=ax1, shrink=1)\n",
        "    pos = ax2.imshow(LV, cmap='RdBu', vmin=-vmin, vmax=vmin,)\n",
        "    fig.colorbar(pos, ax=ax2, shrink=1)\n",
        "    pl.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "normal_token_setup.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
