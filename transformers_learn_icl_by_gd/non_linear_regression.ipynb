{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPNw67eJidgr"
      },
      "source": [
        "# **Transformers learn in-context by gradient descent**\n",
        "This specific notebook can be used to reproduce the non-linear regression task results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install requirements\n",
        "!wget -O requirements.txt https://raw.githubusercontent.com/google-research/self-organising-systems/master/transformers_learn_icl_by_gd/requirements.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FR8YNR-g9JXA"
      },
      "outputs": [],
      "source": [
        "#@title Imports external sources\n",
        "import os\n",
        "import io\n",
        "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
        "import base64\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pylab as pl\n",
        "import numpy as np\n",
        "import glob\n",
        "import requests\n",
        "import random as pyrandom\n",
        "from concurrent import futures\n",
        "from functools import partial\n",
        "from scipy.ndimage import rotate\n",
        "from IPython.display import Image, HTML, clear_output\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "import time\n",
        "from typing import Any, MutableMapping, NamedTuple, Tuple\n",
        "import jax\n",
        "from jax import grad, jit, vmap\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import haiku as hk\n",
        "import math\n",
        "from ml_collections import config_dict\n",
        "import matplotlib.pylab as pl\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.colormaps['Dark2'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "933ztM3DSREA"
      },
      "outputs": [],
      "source": [
        "#@title Import internal sources (from github)\n",
        "!git clone --quiet https://github.com/google-research/self-organising-systems.git /content/self-organising-systems \u003e /dev/null 2\u003e\u00261\n",
        "%cd /content/self-organising-systems/transformers_learn_icl_by_gd\n",
        "from src.transformer import Transformer\n",
        "from src.data import create_reg_data, create_weights\n",
        "from src.config import config\n",
        "from src.train import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4KwAI4LZFfcF"
      },
      "outputs": [],
      "source": [
        "#@title Config\n",
        "num_seeds = 1 #@param {type:\"integer\"}\n",
        "\n",
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "config.local_usage = True\n",
        "config.size_distract = 0\n",
        "config.training_steps = 20000\n",
        "config.training_steps_gd = 20000\n",
        "config.use_softmax = False\n",
        "config.non_linear_reg_task = True\n",
        "\n",
        "####\n",
        "config.deq = True\n",
        "config.gd_deq = True\n",
        "####\n",
        "config.pre_train_gd = True\n",
        "config.train_gd_whitening = False\n",
        "config.train_gd_lr = True\n",
        "####\n",
        "\n",
        "config.layer_norm = False\n",
        "config.out_proj = False\n",
        "config.in_proj = False\n",
        "config.adam = True\n",
        "\n",
        "config.dataset_size = 10\n",
        "config.input_size = 39\n",
        "config.key_size = 40 #config.input_size + 1\n",
        "config.num_layers = 1\n",
        "config.num_heads = 1\n",
        "config.grad_clip_value = 100\n",
        "config.grad_clip_value_gd = 100\n",
        "config.lr = 0.001\n",
        "config.wd = 0.0\n",
        "config.init_scale = 0.002 / config.num_layers\n",
        "config.bs = 2048\n",
        "config.bs_gd_train = 2048\n",
        "config.gd_lr = 0.0003\n",
        "\n",
        "config.dropout_rate = 0.0\n",
        "data_creator = vmap(create_reg_data_sin,\n",
        "                    in_axes=(0, None, None, None, None, None),\n",
        "                    out_axes=0)\n",
        "data_creator_sin_test = vmap(create_reg_data_sin_test, in_axes=(0, None, None,\n",
        "                                                  None, None), out_axes=0)\n",
        "\n",
        "config.y_update = False\n",
        "config.input_range = 10\n",
        "config.seed = 0\n",
        "\n",
        "config.analyse = True\n",
        "config.input_mlp = True\n",
        "config.input_mlp_out_dim = 40\n",
        "config.widening_factor = 4\n",
        "config.sum_norm = False\n",
        "\n",
        "\n",
        "config.in_proj = True\n",
        "config.emb_size = 40\n",
        "config.num_seeds = num_seeds\n",
        "\n",
        "change_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z9P7XZf7rh6l"
      },
      "outputs": [],
      "source": [
        "#@title Utils\n",
        "pl.rcParams.update({'font.size': 12})\n",
        "pl.rc('axes', labelsize=14)\n",
        "pl.rcParams.update({\n",
        "    \"text.usetex\": False,\n",
        "})\n",
        "\n",
        "import matplotlib.colors as mcolors\n",
        "colors = pl.colormaps['Dark2'] \n",
        "def np2pil(a):\n",
        "  if a.dtype in [np.float32, np.float64]:\n",
        "    a = np.uint8(np.clip(a, 0, 1)*255)\n",
        "  return PIL.Image.fromarray(a)\n",
        "\n",
        "def imwrite(f, a, fmt=None):\n",
        "  a = np.asarray(a)\n",
        "  if isinstance(f, str):\n",
        "    fmt = f.rsplit('.', 1)[-1].lower()\n",
        "    if fmt == 'jpg':\n",
        "      fmt = 'jpeg'\n",
        "    f = open(f, 'wb') #GFile.open(f, 'wb')\n",
        "  np2pil(a).save(f, fmt, quality=95)\n",
        "\n",
        "def imencode(a, fmt='jpeg'):\n",
        "  a = np.asarray(a)\n",
        "  if len(a.shape) == 3 and a.shape[-1] == 4:\n",
        "    fmt = 'png'\n",
        "  f = io.BytesIO()\n",
        "  imwrite(f, a, fmt)\n",
        "  return f.getvalue()\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "def grab_plot(close=True):\n",
        "  \"\"\"Return the current Matplotlib figure as an image.\"\"\"\n",
        "  fig = pl.gcf()\n",
        "  fig.canvas.draw()\n",
        "  img = np.array(fig.canvas.renderer._renderer)\n",
        "  a = np.float32(img[..., 3:]/255.0)\n",
        "  img = np.uint8(255*(1.0-a) + img[...,:3] * a)  # alpha\n",
        "  if close:\n",
        "    pl.close()\n",
        "  return img\n",
        "\n",
        "def display_learning(train, test=None, gt=None, inter=None, title=\"train\", \n",
        "                     title1=\"Trained TF\", title2=\"Test\", \n",
        "                     title3='Gradient descent', title4='Interpolated',\n",
        "                     y_label1 = 'L2 Norm', y_label2 = 'Cosine sim',\n",
        "                     y_lim_l=0,  y_lim_u=1, single_seeds= False,\n",
        "                     plot_title = None,\n",
        "                     y_lim_u2= 1., y_lim_l2=0.,  x_label = 'Training steps',   \n",
        "                     second_axis=False, color_add=0, rw=10, num_iter_os=None, \n",
        "                     allow_download=False, plot_num=1, two_plots=False, \n",
        "                     loc_first = 'upper left', label_title=\"Loss\",\n",
        "                     loc_sec='upper left', yscale_log=False, line=\"-\",\n",
        "                     color_axis=False, \n",
        "                     height=3.5, width = 4, ax1=None, ax2=None):\n",
        "  \n",
        "  \"\"\"Update learning curve image.\"\"\"\n",
        "\n",
        "  train_list = train\n",
        "  train = np.array(train)\n",
        "  num_seeds_train = train.shape[0]\n",
        "  train_std = np.std(train, axis=0)\n",
        "  train = np.mean(train, axis=0)\n",
        "  \n",
        "  if test is not None:\n",
        "    test_list = test\n",
        "    test_std = np.std(test, axis=0)\n",
        "    test = np.mean(test, axis=0)\n",
        "\n",
        "  if gt is not None:\n",
        "    gt_list = gt\n",
        "    gt_std = np.std(gt, axis=0)\n",
        "    gt = np.mean(gt, axis=0)\n",
        "\n",
        "  if inter is not None:\n",
        "    inter_list = inter\n",
        "    inter_std = np.std(inter, axis=0)\n",
        "    inter = np.mean(inter, axis=0)\n",
        "\n",
        "  if plot_num == 1:\n",
        "    fig, ax1 = pl.subplots()\n",
        "    ax1.set_xlabel(x_label)\n",
        "    fig.set_size_inches(width, height)\n",
        "\n",
        "  \n",
        "  if test is not None and not second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(test)))\n",
        "    if len(test_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in test_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.1+color_add), alpha=0.2, linewidth='2')\n",
        "      else:\n",
        "        ax1.fill_between(x_range, test-test_std, test+test_std ,alpha=0.2, facecolor=colors(0.1+color_add))\n",
        "    ax1.plot(x_range[:len(test)], test, color=colors(0.1+color_add), label=title2,linewidth='3')\n",
        "    #test_avg = moving_average(test, rw)\n",
        "    #ax1.plot(x_range[:len(test_avg)], test_avg, color=colors(0.1+color_add), label=title2)\n",
        "      \n",
        "  if gt is not None:\n",
        "    if not second_axis:\n",
        "      x_range = np.arange(0, num_iter_os, int(num_iter_os/len(gt)))\n",
        "      #ax1.plot(x_range[:len(gt[:-rw])], gt[:-rw], color=colors(0.2+color_add), alpha=0.3)\n",
        "      #gt_avg = moving_average(gt, rw)\n",
        "      ax1.plot(x_range[:len(gt)],gt, color=colors(0.2+color_add), label=title3,linewidth='3')\n",
        "      if len(gt_list) \u003e 1:\n",
        "        if single_seeds:\n",
        "          for s in gt_list:\n",
        "            ax1.plot(x_range, s, color=colors(0.2+color_add), alpha=0.2, linewidth='2', zorder=0)\n",
        "        else:\n",
        "          ax1.fill_between(x_range, gt-gt_std, gt+gt_std,alpha=0.2, facecolor=colors(0.2+color_add))\n",
        "    else:\n",
        "      x_range = np.arange(0, num_iter_os, int(num_iter_os/len(gt)))\n",
        "      ax1.plot(x_range, gt, color=colors(0.6+color_add), label=title3,linewidth='3')\n",
        "      if len(gt_list) \u003e 1:\n",
        "        if single_seeds:\n",
        "          for s in gt_list:\n",
        "            ax1.plot(x_range, s, color=colors(0.6+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "        else:\n",
        "          ax1.fill_between(x_range, gt-gt_std, gt+gt_std ,alpha=0.2, facecolor=colors(0.6+color_add))\n",
        "\n",
        "  if test is not None and second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(test)))\n",
        "    ax1.plot(x_range[:len(test[:-rw])], test[:-rw], color=colors(0.5+color_add), label=title2,linewidth='3')\n",
        "    #test_avg = moving_average(test, rw)\n",
        "    #ax1.plot(x_range[:len(test_avg)],test_avg, color=colors(0.5+color_add))\n",
        "    if len(test_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in test_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.5+color_add), linewidth='2', alpha=0.3, zorder=0)\n",
        "      else:\n",
        "        ax1.fill_between(x_range, test-test_std, test+test_std ,alpha=0.2, facecolor=colors(0.5+color_add))\n",
        "\n",
        "  if inter is not None and not second_axis:\n",
        "    x_range = np.arange(0, num_iter_os, int(num_iter_os/len(inter)))\n",
        "    ax1.plot(x_range, inter, color=colors(0.4+color_add), label=title4, linewidth='3', zorder=10)\n",
        "    if len(inter_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in inter_list:\n",
        "          ax1.plot(x_range, s, color=colors(0.4+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else:\n",
        "        ax1.fill_between(x_range, inter-inter_std, inter+inter_std ,alpha=0.2, facecolor=colors(0.4+color_add), zorder=1)\n",
        "    #inter_avg = moving_average(inter, rw)\n",
        "    #ax1.plot(x_range[:len(inter_avg)], inter_avg, color=colors(0.7+color_add), label=title4)\n",
        "\n",
        "\n",
        "  if second_axis:\n",
        "    if ax2 is None:\n",
        "      ax2 = ax1.twinx()\n",
        "    ax2.set_zorder(0)\n",
        "    ax1.set_zorder(1)\n",
        "    ax1.set_frame_on(False)\n",
        "    #train_avg = moving_average(train, rw)\n",
        "    #ax2.plot(train[:-rw], color=colors(0.1+color_add), alpha=0.3)\n",
        "    ax2.plot(x_range, train, color=colors(0.4+color_add), label=title1, linewidth='3')\n",
        "    ax2.plot(x_range, np.ones_like(train), \"--\", color=\"gray\", linewidth='0.7')\n",
        "    if len(train_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "        for s in train_list:\n",
        "          ax1.plot(x_range, s, line, color=colors(0.4+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else:\n",
        "        ax2.fill_between(x_range, train-train_std, train+train_std ,alpha=0.2, facecolor=colors(0.4+color_add))\n",
        "\n",
        "    if color_axis:\n",
        "      ax2.yaxis.label.set_color(colors(0.4+color_add))\n",
        "    else:\n",
        "      legend2 = ax2.legend(loc='upper right', framealpha=0.99, facecolor='white')\n",
        "      legend2.set_zorder(100)\n",
        "    ax2.spines['top'].set_visible(False)\n",
        "  else:\n",
        "    #train_avg = moving_average(train, rw)\n",
        "    if line != \"-\":\n",
        "      ax1.scatter(x_range, train, s=[100 for _ in x_range], \n",
        "                  marker=\"+\", color=colors(0.3+color_add), alpha=1, label=title1, zorder=3, linewidths=3)\n",
        "    else:\n",
        "      ax1.plot(x_range, train, line, color=colors(0.3+color_add), label=title1, linewidth='3', zorder=11)\n",
        "    #ax1.plot(x_range[:len(train_avg)], train_avg, line, color=colors(0.3+color_add), label=title1)\n",
        "    if len(train_list) \u003e 1:\n",
        "      if single_seeds:\n",
        "          for s in train_list:\n",
        "            ax1.plot(x_range, s, line, color=colors(0.3+color_add), alpha=0.3, linewidth='2', zorder=0)\n",
        "      else: \n",
        "        ax1.fill_between(x_range, train-train_std, train+train_std,\n",
        "                       alpha=0.5, facecolor=colors(0.3+color_add))\n",
        "\n",
        "    ax1.legend(loc='best', framealpha=1, facecolor='white')\n",
        "    ax1.spines['right'].set_visible(False)\n",
        "    legend = ax1.legend(loc='upper right', framealpha=0.99, facecolor='white')\n",
        "    legend.set_zorder(100)\n",
        "  \n",
        "  legend1 = ax1.legend(loc=loc_first, framealpha=0.99, facecolor='white')\n",
        "  legend1.set_zorder(100)\n",
        "  if second_axis:\n",
        "    ax2.set_ylabel(y_label2)\n",
        "    ax1.set_ylabel(y_label1)\n",
        "    ax1.set_ylim(y_lim_l, y_lim_u)\n",
        "    legend1 = ax1.legend(loc=loc_sec, framealpha=0.99, facecolor='white')\n",
        "    ax2.set_ylim(y_lim_l2, y_lim_u2)\n",
        "    ax1.set_ylim(bottom=0)\n",
        "  else:\n",
        "    pl.ylabel(label_title)\n",
        "    pl.ylim(y_lim_l, y_lim_u)\n",
        "  ax1.spines['top'].set_visible(False)\n",
        "  \n",
        "  if plot_title is not None:\n",
        "    pl.title(plot_title)\n",
        "    \n",
        "  if yscale_log:\n",
        "    ax1.set_yscale(\"log\")\n",
        "  #pl.title(title)\n",
        "  pl.tight_layout()\n",
        "\n",
        "  if allow_download:\n",
        "    if second_axis:\n",
        "      pl.savefig(\"sim.pdf\", format=\"pdf\")\n",
        "      %download_file sim.pdf\n",
        "    else:\n",
        "      pl.savefig(\"train.pdf\", format=\"pdf\")\n",
        "      %download_file train.pdf\n",
        "  else:\n",
        "    img = grab_plot()\n",
        "    display(Image(data=imencode(img, fmt='jpeg')), display_id=title)\n",
        "\n",
        "def sin_plot(preds, eval_data, other_preds = None, title=\"GD\", \n",
        "                y_lim_l=-0.25,  y_lim_u=0.4,\n",
        "                  title_other=\"Tr. TF\", allow_download=False):\n",
        "\n",
        "  pl.rcParams.update({'font.size': 12})\n",
        "  pl.rc('axes', labelsize=14)\n",
        "  pl.rcParams.update({\n",
        "      \"text.usetex\": False,\n",
        "  })\n",
        "\n",
        "  fig, ax1 = pl.subplots()\n",
        "  fig.set_size_inches(6, 3.5)\n",
        "  ax1.set_xlabel('x')\n",
        "  ax1.set_ylabel('y')\n",
        "  ax1.spines['right'].set_visible(False)\n",
        "  ax1.spines['top'].set_visible(False)\n",
        "\n",
        "  phase, amp = eval_data[2] \n",
        "  phase = phase[0][0]\n",
        "  amp = amp[0][0]\n",
        "\n",
        "  x = np.arange(-5, 5, 0.1)\n",
        "  y = np.sin(x + phase)*amp\n",
        "  ax1.plot(x, y, \"--\", color=\"black\", label=\"GT\")\n",
        "\n",
        "\n",
        "  x =  eval_data[0][0][:-1, 0]\n",
        "  y =  eval_data[0][0][:-1, 1]\n",
        "  ax1.plot(x, y, \"*\", color=\"red\", label=\"Data\")\n",
        "\n",
        "  x =  eval_data[1][:, 0]\n",
        "  for step in range(len(preds)):\n",
        "    prec = min([0.9, (step+1)/len(preds)])\n",
        "    sort_x = np.argsort(x)\n",
        "    if step \u003e= 1:\n",
        "      ax1.plot(x[sort_x], preds[step][sort_x], \"-\", color=colors(0.1),\n",
        "             alpha = 0.1 + prec, label=title + \" step \" + str(step))\n",
        "    elif step == 0:\n",
        "      ax1.plot(x[sort_x], preds[step][sort_x], \"-\", color=colors(0.1),\n",
        "             alpha = 0.1 + prec, label=title + \" init\")\n",
        "  if other_preds is not None:\n",
        "    for step in range(len(other_preds)):\n",
        "      prec = min([0.9, (step+1)/len(preds)])\n",
        "      sort_x = np.argsort(x)\n",
        "      if step \u003e= 1:\n",
        "        ax1.plot(x[sort_x], other_preds[step][sort_x], \"-\", color=colors(0.3),\n",
        "              alpha = 0.1 + prec, label=title_other + \" step \" + str(step))\n",
        "      elif step == 0:\n",
        "        ax1.plot(x[sort_x], other_preds[step][sort_x], \"-\", color=colors(0.3),\n",
        "              alpha = 0.1 + prec, label=title_other + \" init\")\n",
        "    legend1 = ax1.legend(ncol=3, loc='upper right', framealpha=0.99, facecolor='white')\n",
        "  else:\n",
        "    legend1 = ax1.legend(ncol=2, loc='upper right', framealpha=0.99, facecolor='white')\n",
        "\n",
        "  pl.ylim(y_lim_l, y_lim_u)\n",
        "  \n",
        "  pl.tight_layout()\n",
        "  if allow_download:\n",
        "    pl.savefig(\"sine_wave.pdf\", format=\"pdf\")\n",
        "    %download_file sine_wave.pdf\n",
        "  else:\n",
        "    img = grab_plot()\n",
        "    display(Image(data=imencode(img, fmt='jpeg')), display_id=title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Li0HaIsW5BFQ"
      },
      "outputs": [],
      "source": [
        "#@title Lists\n",
        "loss_trans_list =  [[]  for _ in range(config.num_seeds)]\n",
        "losses_gd_list =  [[]  for _ in range(config.num_seeds)]\n",
        "p_norm_list =  [[]  for _ in range(config.num_seeds)]\n",
        "grad_norm_list =  [[]  for _ in range(config.num_seeds)]\n",
        "cos_sim_list  =  [[]  for _ in range(config.num_seeds)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7s4jr3OBpaq9"
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "eval_rng = jax.random.PRNGKey(10)\n",
        "for cur_seed in range(config.num_seeds):\n",
        "  if cur_seed == 1:\n",
        "    save_train_params = train_state.params\n",
        "  config.seed = cur_seed  \n",
        "  optimiser, train_state, _, rng = init()\n",
        "  rng, data_rng = jax.random.split(rng, 2)\n",
        "  if config.analyse:\n",
        "    if cur_seed == 0:\n",
        "      #lr_min, min_loss = scan_lrs(eval_rng, lin_diag=False)\n",
        "      #print('Best lr found for gradient descent: ', lr_min/config.dataset_size, min_loss)\n",
        "      params_c = create_weights(config.input_size, 1, config.dataset_size, 0.1,\n",
        "                                jnp.ones([1, 1, config.input_size])*0.0, \n",
        "                                lin_diag=False, gd_deq=config.gd_deq,\n",
        "                                num_layers=config.num_layers, \n",
        "                                input_mlp_rnd=eval_rng if config.input_mlp else None)\n",
        "      if config.pre_train_gd:\n",
        "        params_c, eval_rng = pre_train_gd_hps(eval_rng, params_c)\n",
        "  eval_data = data_creator(jax.random.split(eval_rng, num=config.bs),\n",
        "                               config.input_size,\n",
        "                               config.dataset_size,\n",
        "                               config.size_distract,\n",
        "                               config.input_range,\n",
        "                               config.weight_scale)\n",
        "  \n",
        "  for step in range(config.training_steps):\n",
        "    rng, data_rng = jax.random.split(data_rng, 2)\n",
        "    train_data = data_creator(jax.random.split(rng, num=config.bs), \n",
        "                              config.input_size,\n",
        "                              config.dataset_size,\n",
        "                              config.size_distract,\n",
        "                              config.input_range,\n",
        "                              config.weight_scale)\n",
        "    train_state, metrics = update(train_state, train_data, optimiser)\n",
        "    \n",
        "    #for params in train_state.params:\n",
        "    #  if \"mlp\" in params or 'emb' in params:\n",
        "    #    train_state.params[params] = params_c[params.replace(\"transformer\", \"Transformer_gd\")]\n",
        "    if step % 1000 == 0:\n",
        "      \n",
        "      loss_trans, _, _ = predict_test.apply(train_state.params, eval_rng,\n",
        "                                            eval_data, False)\n",
        "      \n",
        "      loss_trans_list[cur_seed].append(loss_trans)\n",
        "      if config.analyse:\n",
        "        losses_gd, _, _ = predict_test.apply(params_c, eval_rng, eval_data, True)\n",
        "        losses_gd_list[cur_seed].append(losses_gd)\n",
        "\n",
        "        #rng, data_rng, eval_rng = jax.random.split(data_rng, 3)\n",
        "        # Alignment Transformers and GD\n",
        "        cos_sim, w_norm, p_norm = analyse(eval_data, train_state, eval_rng, \n",
        "                                          params_c)\n",
        "        display((\"Current seed\", cur_seed, \"Training step\", step,\n",
        "                    \"Trained MLP with GD\", losses_gd.item(),\n",
        "                    \"Trained MLP with SA layer\", loss_trans.item(),\n",
        "                    \"Cosine sim TF vs GD\", cos_sim.item(), \n",
        "                    \"Diff predictions TF vs GD\", p_norm.item(), \n",
        "                    \"Diff gradients TF vs GD\", w_norm.item()),\n",
        "                    display_id=\"Cur met\")\n",
        "        \n",
        "        cos_sim_list[cur_seed].append(cos_sim)\n",
        "        p_norm_list[cur_seed].append(p_norm)\n",
        "        grad_norm_list[cur_seed].append(w_norm)\n",
        "\n",
        "if config.num_seeds == 1:\n",
        "  save_train_params = train_state.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tWjKF2SgrbTO"
      },
      "outputs": [],
      "source": [
        "#@title Visualize loss and alignment\n",
        "\n",
        "display_learning(loss_trans_list, test=losses_gd_list, y_lim_u=0.01, y_lim_l=0.0,\n",
        "                 rw=1, title=\"train.pdf\", allow_download=False, title3='GD', \n",
        "                 title1='Trained TF', title2='MLP + GD', single_seeds=True,\n",
        "                 num_iter_os=len(loss_trans_list[0])*1000)\n",
        "\n",
        "display_learning(cos_sim_list, grad_norm_list, p_norm_list, title1=\"Partial cosine\",\n",
        "                 title2=\"Partial diff\", y_lim_u=0.08, \n",
        "                 title3=\"Preds diff\", second_axis=True, \n",
        "                 y_lim_u2=1.09999,  color_add=0.2, loc_sec = 'lower left',\n",
        "                 y_lim_l2=0.5,\n",
        "                 rw=1, num_iter_os=len(cos_sim_list[0])*1000, title=\"sim.pdf\",\n",
        "                 allow_download=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MEvXnePuIiDr"
      },
      "outputs": [],
      "source": [
        "#@title Visualize functions before and after GD / SA layer\n",
        "\n",
        "rng, eval_rng = jax.random.split(eval_rng, 2)\n",
        "\n",
        "preds, eval_data = test_sin(params_c, rng, True)\n",
        "preds_tr, eval_data = test_sin(save_train_params, rng, False)\n",
        "sin_plot(preds, eval_data, other_preds=preds_tr, y_lim_l=-0.55, y_lim_u=0.75)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "name": "non_linear_regression",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
